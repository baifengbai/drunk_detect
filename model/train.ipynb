{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout\n",
    "from keras import optimizers\n",
    "from sklearn.utils import shuffle\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(drunkfile, normalfile):\n",
    "    drunk = pd.read_csv(drunkfile)\n",
    "    normal = pd.read_csv(normalfile)\n",
    "    data = pd.concat([drunk, normal])\n",
    "    ans_list = [1]*len(drunk) + [0]*len(normal)\n",
    "    return data[['smile','anger','contempt','disgust','fear','happiness','neutral','sadness','surprise','eyeOccluded']].values, ans_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, Y_train = read_data(\"drunk.csv\", \"normal.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, Y_train = np.array(X_train), np.array(Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train[X_train==True] = 1\n",
    "X_train[X_train==False] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, Y_train) = shuffle(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_valid = X_train[:-50], X_train[-50:]\n",
    "Y_train, Y_valid = Y_train[:-50], Y_train[-50:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1018 samples, validate on 255 samples\n",
      "Epoch 1/100\n",
      "1018/1018 [==============================] - 2s - loss: 0.6363 - acc: 0.6601 - val_loss: 0.6076 - val_acc: 0.6431\n",
      "Epoch 2/100\n",
      "1018/1018 [==============================] - 0s - loss: 0.6122 - acc: 0.6582 - val_loss: 0.5944 - val_acc: 0.6510\n",
      "Epoch 3/100\n",
      "1018/1018 [==============================] - 0s - loss: 0.6113 - acc: 0.6719 - val_loss: 0.5868 - val_acc: 0.6784\n",
      "Epoch 4/100\n",
      "1018/1018 [==============================] - 0s - loss: 0.6082 - acc: 0.6945 - val_loss: 0.5778 - val_acc: 0.7098\n",
      "Epoch 5/100\n",
      "1018/1018 [==============================] - 0s - loss: 0.6057 - acc: 0.6916 - val_loss: 0.5680 - val_acc: 0.7255\n",
      "Epoch 6/100\n",
      "1018/1018 [==============================] - 0s - loss: 0.5923 - acc: 0.6955 - val_loss: 0.5617 - val_acc: 0.7333\n",
      "Epoch 7/100\n",
      "1018/1018 [==============================] - 0s - loss: 0.5925 - acc: 0.7063 - val_loss: 0.5435 - val_acc: 0.7608\n",
      "Epoch 8/100\n",
      "1018/1018 [==============================] - 0s - loss: 0.5812 - acc: 0.7151 - val_loss: 0.5479 - val_acc: 0.7647\n",
      "Epoch 9/100\n",
      "1018/1018 [==============================] - 0s - loss: 0.5570 - acc: 0.7417 - val_loss: 0.5229 - val_acc: 0.7765\n",
      "Epoch 10/100\n",
      "1018/1018 [==============================] - 0s - loss: 0.5550 - acc: 0.7495 - val_loss: 0.5253 - val_acc: 0.7608\n",
      "Epoch 11/100\n",
      "1018/1018 [==============================] - 0s - loss: 0.5322 - acc: 0.7574 - val_loss: 0.4964 - val_acc: 0.7961\n",
      "Epoch 12/100\n",
      "1018/1018 [==============================] - 0s - loss: 0.5340 - acc: 0.7701 - val_loss: 0.5096 - val_acc: 0.7765\n",
      "Epoch 13/100\n",
      "1018/1018 [==============================] - 0s - loss: 0.5240 - acc: 0.7603 - val_loss: 0.4951 - val_acc: 0.7961\n",
      "Epoch 14/100\n",
      "1018/1018 [==============================] - 0s - loss: 0.5271 - acc: 0.7682 - val_loss: 0.4880 - val_acc: 0.8000\n",
      "Epoch 15/100\n",
      "1018/1018 [==============================] - 0s - loss: 0.5218 - acc: 0.7750 - val_loss: 0.4883 - val_acc: 0.8039\n",
      "Epoch 16/100\n",
      "1018/1018 [==============================] - 0s - loss: 0.5132 - acc: 0.7829 - val_loss: 0.4928 - val_acc: 0.7765\n",
      "Epoch 17/100\n",
      "1018/1018 [==============================] - 0s - loss: 0.5098 - acc: 0.7780 - val_loss: 0.4848 - val_acc: 0.7922\n",
      "Epoch 18/100\n",
      "1018/1018 [==============================] - 0s - loss: 0.5186 - acc: 0.7662 - val_loss: 0.5003 - val_acc: 0.7843\n",
      "Epoch 19/100\n",
      "1018/1018 [==============================] - 0s - loss: 0.5031 - acc: 0.7819 - val_loss: 0.4886 - val_acc: 0.7882\n",
      "Epoch 20/100\n",
      "1018/1018 [==============================] - 0s - loss: 0.5059 - acc: 0.7849 - val_loss: 0.4715 - val_acc: 0.8157\n",
      "Epoch 21/100\n",
      "1018/1018 [==============================] - 0s - loss: 0.5160 - acc: 0.7770 - val_loss: 0.4716 - val_acc: 0.8039\n",
      "Epoch 22/100\n",
      "1018/1018 [==============================] - 0s - loss: 0.5152 - acc: 0.7731 - val_loss: 0.4729 - val_acc: 0.8078\n",
      "Epoch 23/100\n",
      "1018/1018 [==============================] - 0s - loss: 0.5047 - acc: 0.7819 - val_loss: 0.4647 - val_acc: 0.8118\n",
      "Epoch 24/100\n",
      "1018/1018 [==============================] - 0s - loss: 0.4972 - acc: 0.7839 - val_loss: 0.4729 - val_acc: 0.8039\n",
      "Epoch 25/100\n",
      "1018/1018 [==============================] - 0s - loss: 0.4904 - acc: 0.7908 - val_loss: 0.4587 - val_acc: 0.8039\n",
      "Epoch 26/100\n",
      "1018/1018 [==============================] - 0s - loss: 0.4866 - acc: 0.7927 - val_loss: 0.4681 - val_acc: 0.8078\n",
      "Epoch 27/100\n",
      "1018/1018 [==============================] - 0s - loss: 0.4813 - acc: 0.7937 - val_loss: 0.4663 - val_acc: 0.8078\n",
      "Epoch 28/100\n",
      "1018/1018 [==============================] - 0s - loss: 0.4732 - acc: 0.8026 - val_loss: 0.4566 - val_acc: 0.8118\n",
      "Epoch 29/100\n",
      "1018/1018 [==============================] - 0s - loss: 0.5009 - acc: 0.7957 - val_loss: 0.4533 - val_acc: 0.8157\n",
      "Epoch 30/100\n",
      "1018/1018 [==============================] - 0s - loss: 0.4903 - acc: 0.7957 - val_loss: 0.4525 - val_acc: 0.8157\n",
      "Epoch 31/100\n",
      "1018/1018 [==============================] - 0s - loss: 0.4882 - acc: 0.7780 - val_loss: 0.4565 - val_acc: 0.8196\n",
      "Epoch 32/100\n",
      "1018/1018 [==============================] - 0s - loss: 0.4882 - acc: 0.7888 - val_loss: 0.4587 - val_acc: 0.8118\n",
      "Epoch 33/100\n",
      "1018/1018 [==============================] - 0s - loss: 0.4858 - acc: 0.7878 - val_loss: 0.4526 - val_acc: 0.8196\n",
      "Epoch 34/100\n",
      "1018/1018 [==============================] - 0s - loss: 0.4924 - acc: 0.7908 - val_loss: 0.4591 - val_acc: 0.8235\n",
      "Epoch 35/100\n",
      "1018/1018 [==============================] - 0s - loss: 0.4950 - acc: 0.7927 - val_loss: 0.4564 - val_acc: 0.8157\n",
      "Epoch 36/100\n",
      "1018/1018 [==============================] - 0s - loss: 0.5020 - acc: 0.7908 - val_loss: 0.4695 - val_acc: 0.8039\n",
      "Epoch 37/100\n",
      "1018/1018 [==============================] - 0s - loss: 0.4898 - acc: 0.7888 - val_loss: 0.4518 - val_acc: 0.8235\n",
      "Epoch 38/100\n",
      "1018/1018 [==============================] - 0s - loss: 0.4806 - acc: 0.7996 - val_loss: 0.4481 - val_acc: 0.8196\n",
      "Epoch 39/100\n",
      "1018/1018 [==============================] - 0s - loss: 0.4886 - acc: 0.7917 - val_loss: 0.4501 - val_acc: 0.8196\n",
      "Epoch 40/100\n",
      "1018/1018 [==============================] - 0s - loss: 0.4824 - acc: 0.7908 - val_loss: 0.4533 - val_acc: 0.8196\n",
      "Epoch 41/100\n",
      "1018/1018 [==============================] - 0s - loss: 0.4802 - acc: 0.8035 - val_loss: 0.4502 - val_acc: 0.8196\n",
      "Epoch 42/100\n",
      "1018/1018 [==============================] - 0s - loss: 0.4869 - acc: 0.7976 - val_loss: 0.4475 - val_acc: 0.8275\n",
      "Epoch 43/100\n",
      "1018/1018 [==============================] - 0s - loss: 0.4782 - acc: 0.8094 - val_loss: 0.4519 - val_acc: 0.8196\n",
      "Epoch 44/100\n",
      "1018/1018 [==============================] - 0s - loss: 0.4806 - acc: 0.8006 - val_loss: 0.4867 - val_acc: 0.8078\n",
      "Epoch 45/100\n",
      "1018/1018 [==============================] - 0s - loss: 0.4796 - acc: 0.7986 - val_loss: 0.4507 - val_acc: 0.8314\n",
      "Epoch 46/100\n",
      "1018/1018 [==============================] - 0s - loss: 0.4900 - acc: 0.7957 - val_loss: 0.4518 - val_acc: 0.8314\n",
      "Epoch 47/100\n",
      "1018/1018 [==============================] - 0s - loss: 0.4783 - acc: 0.8075 - val_loss: 0.4604 - val_acc: 0.8196\n",
      "Epoch 48/100\n",
      "1018/1018 [==============================] - 0s - loss: 0.4845 - acc: 0.7937 - val_loss: 0.4536 - val_acc: 0.8157\n",
      "Epoch 49/100\n",
      "1018/1018 [==============================] - 0s - loss: 0.4826 - acc: 0.7917 - val_loss: 0.4603 - val_acc: 0.8157\n",
      "Epoch 50/100\n",
      "1018/1018 [==============================] - 0s - loss: 0.4942 - acc: 0.7986 - val_loss: 0.4438 - val_acc: 0.8275\n",
      "Epoch 51/100\n",
      "1018/1018 [==============================] - 0s - loss: 0.4773 - acc: 0.7888 - val_loss: 0.4462 - val_acc: 0.8275\n",
      "Epoch 52/100\n",
      "1018/1018 [==============================] - 0s - loss: 0.4859 - acc: 0.8016 - val_loss: 0.4497 - val_acc: 0.8314\n",
      "Epoch 53/100\n",
      "1018/1018 [==============================] - 0s - loss: 0.4766 - acc: 0.7996 - val_loss: 0.4484 - val_acc: 0.8235\n",
      "Epoch 54/100\n",
      "1018/1018 [==============================] - 0s - loss: 0.4796 - acc: 0.7976 - val_loss: 0.4572 - val_acc: 0.8196\n",
      "Epoch 55/100\n",
      "1018/1018 [==============================] - 0s - loss: 0.4709 - acc: 0.8094 - val_loss: 0.4436 - val_acc: 0.8314\n",
      "Epoch 56/100\n",
      "1018/1018 [==============================] - 0s - loss: 0.4793 - acc: 0.8075 - val_loss: 0.4508 - val_acc: 0.8275\n",
      "Epoch 57/100\n",
      "1018/1018 [==============================] - 0s - loss: 0.4718 - acc: 0.7967 - val_loss: 0.4477 - val_acc: 0.8235\n",
      "Epoch 58/100\n",
      "1018/1018 [==============================] - 0s - loss: 0.4727 - acc: 0.7927 - val_loss: 0.4598 - val_acc: 0.8235\n",
      "Epoch 59/100\n",
      "1018/1018 [==============================] - 0s - loss: 0.4810 - acc: 0.8035 - val_loss: 0.4575 - val_acc: 0.8118\n",
      "Epoch 60/100\n",
      "1018/1018 [==============================] - 0s - loss: 0.4793 - acc: 0.8016 - val_loss: 0.4459 - val_acc: 0.8314\n",
      "Epoch 61/100\n",
      "1018/1018 [==============================] - 0s - loss: 0.4618 - acc: 0.8075 - val_loss: 0.4436 - val_acc: 0.8235\n",
      "Epoch 62/100\n",
      "1018/1018 [==============================] - 0s - loss: 0.4766 - acc: 0.7937 - val_loss: 0.4573 - val_acc: 0.8196\n",
      "Epoch 63/100\n",
      "1018/1018 [==============================] - 0s - loss: 0.4756 - acc: 0.7957 - val_loss: 0.4439 - val_acc: 0.8314\n",
      "Epoch 64/100\n",
      "1018/1018 [==============================] - 0s - loss: 0.4702 - acc: 0.8016 - val_loss: 0.4395 - val_acc: 0.8314\n",
      "Epoch 65/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1018/1018 [==============================] - 0s - loss: 0.4810 - acc: 0.7937 - val_loss: 0.4481 - val_acc: 0.8196\n",
      "Epoch 66/100\n",
      "1018/1018 [==============================] - 0s - loss: 0.4663 - acc: 0.8065 - val_loss: 0.4429 - val_acc: 0.8314\n",
      "Epoch 67/100\n",
      "1018/1018 [==============================] - 0s - loss: 0.4843 - acc: 0.7908 - val_loss: 0.4468 - val_acc: 0.8275\n",
      "Epoch 68/100\n",
      "1018/1018 [==============================] - 0s - loss: 0.4745 - acc: 0.7947 - val_loss: 0.4437 - val_acc: 0.8314\n",
      "Epoch 69/100\n",
      "1018/1018 [==============================] - 0s - loss: 0.4753 - acc: 0.7986 - val_loss: 0.4422 - val_acc: 0.8314\n",
      "Epoch 70/100\n",
      "1018/1018 [==============================] - 0s - loss: 0.4900 - acc: 0.7839 - val_loss: 0.4517 - val_acc: 0.8196\n",
      "Epoch 71/100\n",
      "1018/1018 [==============================] - 0s - loss: 0.4723 - acc: 0.8026 - val_loss: 0.4471 - val_acc: 0.8392\n",
      "Epoch 72/100\n",
      "1018/1018 [==============================] - 0s - loss: 0.4766 - acc: 0.8055 - val_loss: 0.4482 - val_acc: 0.8157\n",
      "Epoch 73/100\n",
      "1018/1018 [==============================] - 0s - loss: 0.4758 - acc: 0.8055 - val_loss: 0.4372 - val_acc: 0.8392\n",
      "Epoch 74/100\n",
      "1018/1018 [==============================] - 0s - loss: 0.4772 - acc: 0.8153 - val_loss: 0.4438 - val_acc: 0.8196\n",
      "Epoch 75/100\n",
      "1018/1018 [==============================] - 0s - loss: 0.4674 - acc: 0.7996 - val_loss: 0.4418 - val_acc: 0.8314\n",
      "Epoch 76/100\n",
      "1018/1018 [==============================] - 0s - loss: 0.4696 - acc: 0.8084 - val_loss: 0.4429 - val_acc: 0.8235\n",
      "Epoch 77/100\n",
      "1018/1018 [==============================] - 0s - loss: 0.4778 - acc: 0.8094 - val_loss: 0.4574 - val_acc: 0.8196\n",
      "Epoch 78/100\n",
      "1018/1018 [==============================] - 0s - loss: 0.4723 - acc: 0.7976 - val_loss: 0.4429 - val_acc: 0.8353\n",
      "Epoch 79/100\n",
      "1018/1018 [==============================] - 0s - loss: 0.4636 - acc: 0.8094 - val_loss: 0.4429 - val_acc: 0.8314\n",
      "Epoch 80/100\n",
      "1018/1018 [==============================] - 0s - loss: 0.4694 - acc: 0.8084 - val_loss: 0.4436 - val_acc: 0.8196\n",
      "Epoch 81/100\n",
      "1018/1018 [==============================] - 0s - loss: 0.4616 - acc: 0.8212 - val_loss: 0.4384 - val_acc: 0.8392\n",
      "Epoch 82/100\n",
      "1018/1018 [==============================] - 0s - loss: 0.4613 - acc: 0.8084 - val_loss: 0.4483 - val_acc: 0.8235\n",
      "Epoch 83/100\n",
      "1018/1018 [==============================] - 0s - loss: 0.4755 - acc: 0.8055 - val_loss: 0.4455 - val_acc: 0.8196\n",
      "Epoch 84/100\n",
      "1018/1018 [==============================] - 0s - loss: 0.4675 - acc: 0.8045 - val_loss: 0.4387 - val_acc: 0.8392\n",
      "Epoch 85/100\n",
      "1018/1018 [==============================] - 0s - loss: 0.4587 - acc: 0.8134 - val_loss: 0.4366 - val_acc: 0.8353\n",
      "Epoch 86/100\n",
      "1018/1018 [==============================] - 0s - loss: 0.4716 - acc: 0.8084 - val_loss: 0.4361 - val_acc: 0.8353\n",
      "Epoch 87/100\n",
      "1018/1018 [==============================] - 0s - loss: 0.4607 - acc: 0.8065 - val_loss: 0.4355 - val_acc: 0.8314\n",
      "Epoch 88/100\n",
      "1018/1018 [==============================] - 0s - loss: 0.4520 - acc: 0.8143 - val_loss: 0.4424 - val_acc: 0.8314\n",
      "Epoch 89/100\n",
      "1018/1018 [==============================] - 0s - loss: 0.4759 - acc: 0.7927 - val_loss: 0.4365 - val_acc: 0.8353\n",
      "Epoch 90/100\n",
      "1018/1018 [==============================] - 0s - loss: 0.4726 - acc: 0.8035 - val_loss: 0.4479 - val_acc: 0.8235\n",
      "Epoch 91/100\n",
      "1018/1018 [==============================] - 0s - loss: 0.4611 - acc: 0.8094 - val_loss: 0.4489 - val_acc: 0.8157\n",
      "Epoch 92/100\n",
      "1018/1018 [==============================] - 0s - loss: 0.4631 - acc: 0.8163 - val_loss: 0.4537 - val_acc: 0.8235\n",
      "Epoch 93/100\n",
      "1018/1018 [==============================] - 0s - loss: 0.4528 - acc: 0.8134 - val_loss: 0.4360 - val_acc: 0.8392\n",
      "Epoch 94/100\n",
      "1018/1018 [==============================] - 0s - loss: 0.4753 - acc: 0.7917 - val_loss: 0.4345 - val_acc: 0.8392\n",
      "Epoch 95/100\n",
      "1018/1018 [==============================] - 0s - loss: 0.4674 - acc: 0.8035 - val_loss: 0.4411 - val_acc: 0.8353\n",
      "Epoch 96/100\n",
      "1018/1018 [==============================] - 0s - loss: 0.4651 - acc: 0.8153 - val_loss: 0.4492 - val_acc: 0.8353\n",
      "Epoch 97/100\n",
      "1018/1018 [==============================] - 0s - loss: 0.4668 - acc: 0.8084 - val_loss: 0.4389 - val_acc: 0.8392\n",
      "Epoch 98/100\n",
      "1018/1018 [==============================] - 0s - loss: 0.4555 - acc: 0.8173 - val_loss: 0.4368 - val_acc: 0.8314\n",
      "Epoch 99/100\n",
      "1018/1018 [==============================] - 0s - loss: 0.4861 - acc: 0.8065 - val_loss: 0.4404 - val_acc: 0.8392\n",
      "Epoch 100/100\n",
      "1018/1018 [==============================] - 0s - loss: 0.4570 - acc: 0.8104 - val_loss: 0.4402 - val_acc: 0.8353\n",
      "50/50 [==============================] - 0s\n",
      "0.839999973774\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(input_dim = X_train.shape[1], units = 10, activation = 'relu'))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(units = 64, activation = 'relu'))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(units = 32, activation = 'relu'))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(units = 8, activation = 'relu'))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(units = 1, activation = 'sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='Adam', metrics=['accuracy'])\n",
    "# callbacks = []\n",
    "# callbacks.append(ModelCheckpoint('models/model-{epoch:05d}-{val_acc:.5f}-{val_loss:.5f}.npy', monitor='val_acc', save_best_only=True, mode = 'auto', period=1))\n",
    "# model.fit(X_train, Y_train, batch_size = 8, epochs = 100, validation_split=0.2, callbacks=callbacks)\n",
    "model.fit(X_train, Y_train, batch_size = 8, epochs = 100, validation_split=0.2)\n",
    "result = model.evaluate(X_valid, Y_valid, batch_size = X_valid.shape[0])\n",
    "print(result[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc_train =  0.862529457973\n",
      "acc_valid =  0.82\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python36\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "model2 = XGBClassifier(max_depth=3, n_estimators=200, learning_rate=0.05)\n",
    "model2.fit(X_train, Y_train.flatten())\n",
    "predict_train = model2.predict(X_train)\n",
    "acc_train = np.mean(Y_train.flatten() == predict_train)\n",
    "print(\"acc_train = \", acc_train)\n",
    "predict_valid = model2.predict(X_valid)\n",
    "acc_valid = np.mean(Y_valid.flatten() == predict_valid)\n",
    "print(\"acc_valid = \", acc_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50/50 [==============================] - 0s\n",
      "0.839999973774\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "model = load_model(\"keras_model.h5\")\n",
    "result = model.evaluate(X_valid, Y_valid, batch_size = X_valid.shape[0])\n",
    "print(result[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
