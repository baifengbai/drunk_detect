{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout\n",
    "from keras import optimizers\n",
    "from sklearn.utils import shuffle\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(drunkfile, normalfile):\n",
    "    drunk = pd.read_csv(drunkfile)\n",
    "    normal = pd.read_csv(normalfile)\n",
    "    data = pd.concat([drunk, normal])\n",
    "    ans_list = [1]*len(drunk) + [0]*len(normal)\n",
    "    return data[['smile','anger','contempt','disgust','fear','happiness','neutral','sadness','surprise','eyeOccluded']].values, ans_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, Y_train = read_data(\"drunk.csv\", \"normal.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, Y_train = np.array(X_train), np.array(Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train[X_train==True] = 1\n",
    "X_train[X_train==False] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, Y_train) = shuffle(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_valid = X_train[:-50], X_train[-50:]\n",
    "Y_train, Y_valid = Y_train[:-50], Y_train[-50:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# model = Sequential()\n",
    "# model.add(Dense(input_dim = X_train.shape[1], units = 10, activation = 'relu'))\n",
    "# model.add(Dropout(0.25))\n",
    "# model.add(Dense(units = 64, activation = 'relu'))\n",
    "# model.add(Dropout(0.25))\n",
    "# model.add(Dense(units = 32, activation = 'relu'))\n",
    "# model.add(Dropout(0.25))\n",
    "# model.add(Dense(units = 8, activation = 'relu'))\n",
    "# model.add(Dropout(0.25))\n",
    "# model.add(Dense(units = 1, activation = 'sigmoid'))\n",
    "# model.compile(loss='binary_crossentropy', optimizer='Adam', metrics=['accuracy'])\n",
    "# callbacks = []\n",
    "# callbacks.append(ModelCheckpoint('models/model-{epoch:05d}-{val_acc:.5f}-{val_loss:.5f}.npy', monitor='val_acc', save_best_only=True, mode = 'auto', period=1))\n",
    "# model.fit(X_train, Y_train, batch_size = 8, epochs = 100, validation_split=0.2, callbacks=callbacks)\n",
    "# result = model.evaluate(X_valid, Y_valid, batch_size = X_valid.shape[0])\n",
    "# print(result[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc_train =  0.862529457973\n",
      "acc_valid =  0.78\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python36\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "model2 = XGBClassifier(max_depth=3, n_estimators=200, learning_rate=0.05)\n",
    "model2.fit(X_train, Y_train.flatten())\n",
    "predict_train = model2.predict(X_train)\n",
    "acc_train = np.mean(Y_train.flatten() == predict_train)\n",
    "print(\"acc_train = \", acc_train)\n",
    "predict_valid = model2.predict(X_valid)\n",
    "acc_valid = np.mean(Y_valid.flatten() == predict_valid)\n",
    "print(\"acc_valid = \", acc_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50/50 [==============================] - 0s\n",
      "0.77999997139\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "model = load_model(\"keras_model.h5\")\n",
    "result = model.evaluate(X_valid, Y_valid, batch_size = X_valid.shape[0])\n",
    "print(result[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
